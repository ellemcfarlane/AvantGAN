{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AvantGan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UOLarGaaXwX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "842b71e5-c163-460b-ab76-a47a6adfcfab"
      },
      "source": [
        "# Elle McFarlane\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "else:\n",
        "    device_name = 'CPU:0'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-eebf3cb919a6>:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vwg20CP-E1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip data\n",
        "drawings_archive_path = '/content/avantgarde_drawings.zip'\n",
        "shutil.unpack_archive(drawings_archive_path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVQ61mmI_cYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Config class needed for DataManager and GAN classes\n",
        "class Config:\n",
        "    def from_json(config_path):\n",
        "        with open(config_path, \"r\") as config_file:\n",
        "          config = json.load(config_file)\n",
        "        return config"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9WNZxKvRiMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DataManager class for Image, Z-vec Data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "import json\n",
        "\n",
        "class DataManager:\n",
        "    def __init__(self, config_file):\n",
        "        config = Config.from_json(config_file)\n",
        "        self.image_dims = config['image_dims']\n",
        "        self.n_pnts = config['n_pnts']\n",
        "        self.batch_size = config['batch_size']\n",
        "        self.n_batches = config['n_pnts']//self.batch_size\n",
        "        self.z_size = config['z_size']\n",
        "        self.vec_mode = config['z_vec_mode']\n",
        "        self.data_dir = config['data_dir']\n",
        "\n",
        "        if self.vec_mode == 'uniform':\n",
        "            self.fixed_z = tf.random.uniform(\n",
        "                shape=(self.batch_size, self.z_size),\n",
        "                minval=-1, maxval=1)\n",
        "        elif self.vec_mode == 'normal':\n",
        "            self.fixed_z = tf.random.normal(\n",
        "                shape=(self.batch_size, self.z_size))\n",
        "\n",
        "    def prepare_data(self):\n",
        "        image_len, image_height = self.image_dims[0], self.image_dims[1]\n",
        "        image_size = image_len, image_height\n",
        "\n",
        "        train_datagen = ImageDataGenerator(preprocessing_function=DataManager.rescale)\n",
        "\n",
        "        shared_imgs = train_datagen.flow_from_directory(self.data_dir,\n",
        "                                                    target_size=image_size,\n",
        "                                                    batch_size=self.batch_size,\n",
        "                                                    shuffle=False)\n",
        "\n",
        "        disc_imgs = train_datagen.flow_from_directory(self.data_dir,\n",
        "                                                          target_size=image_size,\n",
        "                                                          batch_size=self.batch_size,\n",
        "                                                          shuffle=False)\n",
        "\n",
        "        shared_data = tf.data.Dataset.from_generator(\n",
        "            lambda: shared_imgs,\n",
        "            output_types=(tf.float32, tf.float32),\n",
        "            output_shapes = ([None,image_len,image_len,3],\n",
        "                            [None,1]))\n",
        "\n",
        "        disc_data = tf.data.Dataset.from_generator(\n",
        "            lambda: disc_imgs,\n",
        "            output_types=(tf.float32, tf.float32),\n",
        "            output_shapes = ([None,image_len,image_len,3],\n",
        "                            [None,1]))\n",
        "\n",
        "        input_zs = self.get_noise_vecs()\n",
        "        shared_data_iter = list(tf.data.Dataset.zip((input_zs, shared_data)).as_numpy_iterator())\n",
        "        disc_data_iter = list(tf.data.Dataset.zip((input_zs, disc_data)).as_numpy_iterator())\n",
        "\n",
        "        # shuffle data\n",
        "        np.random.shuffle(shared_data_iter)\n",
        "        np.random.shuffle(disc_data_iter)\n",
        "\n",
        "        self.shared_data_iter = shared_data_iter\n",
        "        self.disc_data_iter = disc_data_iter\n",
        "\n",
        "\n",
        "    def rescale(image):\n",
        "        \"puts color values in [-1,1] range\"\n",
        "        return (image/255.)*2.-1\n",
        "\n",
        "    def get_noise_vector(self):\n",
        "        'noise vector for the generator input'\n",
        "        if self.vec_mode == 'uniform':\n",
        "            input_z = tf.random.uniform(\n",
        "                shape=(self.z_size,), minval=-1.0, maxval=1.0)\n",
        "        elif self.vec_mode == 'normal':\n",
        "            input_z = tf.random.normal(shape=(self.z_size,))\n",
        "        return input_z\n",
        "\n",
        "    def get_noise_vecs(self):\n",
        "        X = list(range(self.n_pnts))\n",
        "        input_zs = tf.data.Dataset.from_tensor_slices(X)\n",
        "        input_zs = input_zs.map(lambda x: self.get_noise_vector())\n",
        "        input_zs = input_zs.batch(self.batch_size, drop_remainder=False)\n",
        "        return input_zs\n",
        "\n",
        "    def is_aligned(data):\n",
        "        \"makes sure each image has a z_vector in each batch\"\n",
        "        for batch_i, (z_vecs, (imgs,_)) in enumerate(data):\n",
        "          if len(z_vecs) != len(imgs):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def shuffle_shared_data(self):\n",
        "        np.random.shuffle(self.shared_data_iter)\n",
        "\n",
        "    def get_shared_data_iter(self):\n",
        "        return self.shared_data_iter\n",
        "\n",
        "    def get_disc_data(self, n_pnt_to_retrieve):\n",
        "        np.random.shuffle(self.disc_data_iter)\n",
        "        for i in range(n_pnt_to_retrieve):\n",
        "            yield self.disc_data_iter[i]\n",
        "\n",
        "    def get_fixed_z(self):\n",
        "        return self.fixed_z\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    def is_data_valid(self):\n",
        "        return DataManager.is_aligned(self.disc_data_iter) and \\\n",
        "              DataManager.is_aligned(self.shared_data_iter)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAV2x4pq-zyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classes for both GAN networks\n",
        "from abc import ABC, abstractmethod\n",
        "import json\n",
        "\n",
        "class BaseModel(ABC):\n",
        "    \"\"\"Abstract Model class\"\"\"\n",
        "    def __init__(self, config_file):\n",
        "          self.config = Config.from_json(config_file)\n",
        "          self.config['size_factor'] = 2**self.config['n_blocks']\n",
        "          self.config['hidden']['size'] = (\n",
        "            self.config['img_size'][0]//self.config['size_factor'], \n",
        "            self.config['img_size'][1]//self.config['size_factor']\n",
        "          )\n",
        "\n",
        "    @abstractmethod\n",
        "    def build(self):\n",
        "      pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def add_output_layer(self):\n",
        "      pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def build_model_with_base_layers(self):\n",
        "      pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def train(self):\n",
        "      pass\n",
        "\n",
        "class GeneratorDCGAN(BaseModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(\n",
        "            learning_rate=self.config['optimizer']['learning_rate'],\n",
        "            beta_1=self.config['optimizer']['beta_1'],\n",
        "            beta_2=self.config['optimizer']['beta_2'])\n",
        "\n",
        "    def set_discriminator(self, disc_model):\n",
        "        self.disc_model = disc_model\n",
        "\n",
        "    def get_discriminator(self):\n",
        "        return self.disc_model\n",
        "\n",
        "    def add_output_layer(self):         \n",
        "        self.model.add(\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=self.config['img_size'][2],\n",
        "                kernel_size=self.config['output']['kernel_size'], \n",
        "                strides=self.config['output']['strides'],\n",
        "                padding=self.config['output']['padding'],\n",
        "                use_bias=self.config['output']['use_bias'], \n",
        "                activation=self.config['output']['activation']))\n",
        "    \n",
        "    def build_model_with_base_layers(self):\n",
        "        partial_model = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Input(shape=(self.config['z_size'])),\n",
        "                  tf.keras.layers.Dense(\n",
        "                      units=self.config['n_filters'] \\\n",
        "                      *np.prod(self.config['hidden']['size']), \n",
        "                      use_bias=self.config['base']['dense']['use_bias']),\n",
        "                  tf.keras.layers.BatchNormalization(),\n",
        "                  tf.keras.layers.LeakyReLU(),\n",
        "                  tf.keras.layers.Reshape(\n",
        "                      (self.config['hidden']['size'][0],\n",
        "                      self.config['hidden']['size'][1],\n",
        "                      self.config['n_filters'])),\n",
        "                  tf.keras.layers.Conv2DTranspose(\n",
        "                      filters=self.config['n_filters'],\n",
        "                      kernel_size=self.config['base']['tconv']['kernel_size'],\n",
        "                      strides=self.config['base']['tconv']['strides'],\n",
        "                      padding=self.config['base']['tconv']['padding'],\n",
        "                      use_bias=self.config['base']['tconv']['use_bias']),\n",
        "                  tf.keras.layers.BatchNormalization(),\n",
        "                  tf.keras.layers.LeakyReLU()\n",
        "              ])\n",
        "        self.model = partial_model\n",
        "\n",
        "    def add_hidden_blocks(self):\n",
        "        curr_n_filters = self.config['n_filters']\n",
        "        for i in range(self.config['n_blocks']):\n",
        "            curr_n_filters = curr_n_filters // 2\n",
        "            self.model.add(\n",
        "              tf.keras.layers.Conv2DTranspose(\n",
        "              filters=curr_n_filters,\n",
        "              kernel_size=self.config['hidden']['kernel_size'],\n",
        "              strides=self.config['hidden']['strides'],\n",
        "              padding=self.config['hidden']['padding'],\n",
        "              use_bias=self.config['hidden']['use_bias']))\n",
        "            self.model.add(tf.keras.layers.BatchNormalization())\n",
        "            self.model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    def build(self):\n",
        "        self.build_model_with_base_layers()\n",
        "        self.add_hidden_blocks()\n",
        "        self.add_output_layer()\n",
        "\n",
        "    def train(self, input_vec):\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_img = self.__train(input_vec)\n",
        "            disc_pred = self.get_discriminator().predict(fake_img)\n",
        "            loss = -tf.math.reduce_mean(disc_pred)\n",
        "        \n",
        "        grads = tape.gradient(loss, gen_model.get_trainable_variables())\n",
        "        gen_model.get_optimizer().apply_gradients(zip(grads, gen_model.get_trainable_variables()))\n",
        "        return loss\n",
        "\n",
        "    def __train(self, input_vec):\n",
        "        return self.model(input_vec, training=True)\n",
        "\n",
        "    def apply_gradients(self, grads):\n",
        "        self.get_optimizer().apply_gradients(\n",
        "          grads_and_vars=zip(grads, self.model.trainable_variables))\n",
        "        \n",
        "    def generate(self, input_vec):\n",
        "        img = self.model(input_vec, training=False)\n",
        "        return img\n",
        "\n",
        "    def get_trainable_variables(self):\n",
        "        return self.model.trainable_variables\n",
        "\n",
        "    def get_optimizer(self):\n",
        "        return self.optimizer\n",
        "\n",
        "    def create_samples(self, input_z, batch_size):\n",
        "        fake_imgs = self.generate(input_z)\n",
        "        images = tf.reshape(fake_imgs, (batch_size, *self.config['img_size']))    \n",
        "        # convert scale from [-1,1] back to [0,1]\n",
        "        return (images+1)/2.0\n",
        "\n",
        "class DiscriminatorDCGAN(BaseModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(\n",
        "            learning_rate=self.config['optimizer']['learning_rate'],\n",
        "            beta_1=self.config['optimizer']['beta_1'],\n",
        "            beta_2=self.config['optimizer']['beta_2'])\n",
        "\n",
        "    def set_generator(self, gen_model):\n",
        "        self.gen_model = gen_model\n",
        "\n",
        "    def get_generator(self):\n",
        "        return self.gen_model\n",
        "\n",
        "    def build(self):\n",
        "        self.build_model_with_base_layers()\n",
        "        self.add_hidden_blocks()\n",
        "        self.add_output_layer()\n",
        "\n",
        "    def build_model_with_base_layers(self):\n",
        "        partial_model = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Input(shape=(self.config['img_size'])),\n",
        "                  tf.keras.layers.Conv2D(\n",
        "                      filters=self.config['base']['conv']['n_filters'],\n",
        "                      kernel_size=self.config['base']['conv']['kernel_size'], \n",
        "                      strides=self.config['base']['conv']['strides'],\n",
        "                      padding=self.config['base']['conv']['padding']),\n",
        "                  tf.keras.layers.BatchNormalization(),\n",
        "                  tf.keras.layers.LeakyReLU()\n",
        "              ])\n",
        "        self.model = partial_model\n",
        "\n",
        "    def add_hidden_blocks(self):\n",
        "        curr_n_filters = self.config['n_filters']\n",
        "        for i in range(self.config['n_blocks']):\n",
        "            curr_n_filters = curr_n_filters * 2\n",
        "            self.model.add(\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=curr_n_filters,\n",
        "                    kernel_size=self.config['hidden']['kernel_size'], \n",
        "                    strides=self.config['hidden']['strides'],\n",
        "                    padding=self.config['hidden']['padding']))\n",
        "            self.model.add(tf.keras.layers.BatchNormalization())\n",
        "            self.model.add(tf.keras.layers.LeakyReLU())\n",
        "            self.model.add(tf.keras.layers.\n",
        "                           Dropout(self.config['hidden']\n",
        "                                              ['dropout_rate']))\n",
        "\n",
        "    def add_output_layer(self):\n",
        "        self.model.add(tf.keras.layers.Conv2D(\n",
        "          filters=self.config['output']['n_filters'],\n",
        "          kernel_size=self.config['hidden']['size'],\n",
        "          padding=self.config['output']['padding']))        \n",
        "        self.model.add(tf.keras.layers.Reshape((1,)))\n",
        "\n",
        "    def train(self, real_img, input_z):\n",
        "        with tf.GradientTape() as tape:\n",
        "            fake_img = self.get_generator().generate(input_z)\n",
        "            pred_real = disc_model.__train(real_img)\n",
        "            pred_fake = disc_model.__train(fake_img)\n",
        "\n",
        "            # Compute losses\n",
        "            loss_real = -tf.math.reduce_mean(pred_real)\n",
        "            loss_fake =  tf.math.reduce_mean(pred_fake)\n",
        "            tot_loss = loss_real + loss_fake\n",
        "\n",
        "            # Calculate gradient penalty\n",
        "            with tf.GradientTape() as gp_tape:\n",
        "                alpha = tf.random.uniform(\n",
        "                    shape=[pred_real.shape[0], 1, 1, 1], \n",
        "                    minval=0, maxval=1.0)\n",
        "                interpolated = (alpha*real_img + (1-alpha)*fake_img)\n",
        "                gp_tape.watch(interpolated)\n",
        "                critic_intp = disc_model.predict(interpolated)\n",
        "\n",
        "            grads_intp = gp_tape.gradient(\n",
        "                critic_intp, [interpolated,])[0]\n",
        "            grads_intp_l2 = tf.sqrt(\n",
        "                tf.reduce_sum(tf.square(grads_intp), axis=[1, 2, 3]))\n",
        "            grad_penalty = tf.reduce_mean(tf.square(grads_intp_l2 - 1.0))\n",
        "\n",
        "            # Apply gradient penalty\n",
        "            tot_loss += tot_loss + self.config['lambda_gp']*grad_penalty\n",
        "\n",
        "        # Compute and apply the gradients\n",
        "        grads = tape.gradient(tot_loss, disc_model.get_trainable_variables())\n",
        "        self.get_optimizer().apply_gradients(\n",
        "            grads_and_vars=zip(grads, disc_model.get_trainable_variables()))\n",
        "        \n",
        "        return tot_loss, loss_real, loss_fake\n",
        "\n",
        "    def __train(self, input_img):\n",
        "        return self.model(input_img, training=True)\n",
        "\n",
        "    def apply_gradients(self, grads):\n",
        "        self.get_optimizer().apply_gradients(\n",
        "          grads_and_vars=zip(grads, self.model.trainable_variables))\n",
        "        \n",
        "    def predict(self, input_img):\n",
        "        verdict = self.model(input_img, training=False)\n",
        "        return verdict\n",
        "\n",
        "    def get_trainable_variables(self):\n",
        "        return self.model.trainable_variables\n",
        "\n",
        "    def get_optimizer(self):\n",
        "        return self.optimizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90wUJKMChsZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9be079a7-c04c-47fc-c157-b6fb509e9b03"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Set up data\n",
        "    data_manager = DataManager('data_config.json')\n",
        "    data_manager.prepare_data()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9930 images belonging to 1 classes.\n",
            "Found 9930 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QLfDbJnVyV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    # Set up GAN architecture\n",
        "    with tf.device(device_name):\n",
        "        gen_model = GeneratorDCGAN('generator_config.json')\n",
        "        gen_model.build()\n",
        "\n",
        "        disc_model = DiscriminatorDCGAN('discriminator_config.json')\n",
        "        disc_model.build()\n",
        "\n",
        "        gen_model.set_discriminator(disc_model)\n",
        "        disc_model.set_generator(gen_model)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfKlzlbcJsSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "47bafb25-eec7-46db-c34a-cdd448991cdd"
      },
      "source": [
        "    all_losses = []\n",
        "    epoch_samples = []\n",
        "    critic_rounds_per_generator = 5\n",
        "    n_epochs = 200\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        epoch_losses = []\n",
        "        data_manager.shuffle_shared_data()\n",
        "        for batch_i, (z_vec, (real_img, _)) in enumerate(data_manager.get_shared_data_iter()):\n",
        "            if (batch_i % 50) == 0:\n",
        "                print(\"batch\", batch_i)\n",
        "            # only train the discriminator\n",
        "            for bonus_z_vec, (bonus_real_img, _) in data_manager.get_disc_data(critic_rounds_per_generator):\n",
        "                disc_model.train(bonus_real_img, bonus_z_vec)\n",
        "            # train both discriminator and generator\n",
        "            d_loss, d_loss_real, d_loss_fake = disc_model.train(real_img, z_vec)\n",
        "            g_loss = gen_model.train(z_vec)\n",
        "\n",
        "            epoch_losses.append(\n",
        "                (g_loss.numpy(), d_loss.numpy(), \n",
        "                  d_loss_real.numpy(), d_loss_fake.numpy()))\n",
        "                            \n",
        "            all_losses.append(epoch_losses)\n",
        "\n",
        "        print('Epoch {:-3d} | Est. Time {:.2f} min | Avg Losses >>'\n",
        "              ' G/D {:6.2f}/{:6.2f} [D-Real: {:6.2f} D-Fake: {:6.2f}]'\n",
        "              .format(epoch, (time.time() - start_time)/60, \n",
        "                      *list(np.mean(all_losses[-1], axis=0)))\n",
        "        )\n",
        "\n",
        "        epoch_samples.append(\n",
        "            gen_model.create_samples(data_manager.get_fixed_z(),\n",
        "                                    data_manager.get_batch_size()).numpy()\n",
        "        )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6110bfd4959b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# only train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbonus_z_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbonus_real_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_disc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_rounds_per_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mdisc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbonus_real_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbonus_z_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# train both discriminator and generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ad651e1bc189>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, real_img, input_z)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         self.get_optimizer().apply_gradients(\n\u001b[0;32m--> 218\u001b[0;31m             grads_and_vars=zip(grads, disc_model.get_trainable_variables()))\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtot_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \"ParameterServerStrategy and CentralStorageStrategy\")\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m       \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mreduced_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mlocal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mbeta_1_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0mbeta_2_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'beta_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mbeta_1_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_1_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_hyper\u001b[0;34m(self, name, dtype)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    921\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   1853\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   1854\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1855\u001b[0;31m         x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[1;32m   1856\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}