{"cells":[{"cell_type":"markdown","metadata":{},"source":["# StyleGAN3 on Rei Kawakubo Outfits"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-19T09:55:00.963441Z","iopub.status.busy":"2024-06-19T09:55:00.963088Z","iopub.status.idle":"2024-06-19T09:55:02.891209Z","shell.execute_reply":"2024-06-19T09:55:02.889640Z","shell.execute_reply.started":"2024-06-19T09:55:00.963412Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'stylegan3'...\n","remote: Enumerating objects: 212, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n","Receiving objects: 100% (212/212), 4.16 MiB | 19.83 MiB/s, done.\n","Resolving deltas: 100% (101/101), done.\n"]}],"source":["!git clone https://github.com/NVlabs/stylegan3.git"]},{"cell_type":"markdown","metadata":{},"source":["### resize images for training efficiency"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:55:44.408271Z","iopub.status.busy":"2024-06-19T09:55:44.407849Z","iopub.status.idle":"2024-06-19T09:55:46.708910Z","shell.execute_reply":"2024-06-19T09:55:46.707499Z","shell.execute_reply.started":"2024-06-19T09:55:44.408224Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 36.18it/s]\n"]}],"source":["!python /kaggle/working/stylegan3/dataset_tool.py --source=/kaggle/input/avantgarde-highres/super_res_avantgarde --dest=smaller_avantgarde_128.zip --resolution=128x128"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:55:58.141084Z","iopub.status.busy":"2024-06-19T09:55:58.140665Z","iopub.status.idle":"2024-06-19T09:55:59.170344Z","shell.execute_reply":"2024-06-19T09:55:59.169028Z","shell.execute_reply.started":"2024-06-19T09:55:58.141049Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /kaggle/working/smaller_avantgarde_128.zip\n"," extracting: 00000/img00000000.png   \n"," extracting: 00000/img00000001.png   \n"," extracting: 00000/img00000002.png   \n"," extracting: 00000/img00000003.png   \n"," extracting: 00000/img00000004.png   \n"," extracting: 00000/img00000005.png   \n"," extracting: 00000/img00000006.png   \n"," extracting: 00000/img00000007.png   \n"," extracting: 00000/img00000008.png   \n"," extracting: 00000/img00000009.png   \n"," extracting: 00000/img00000010.png   \n"," extracting: 00000/img00000011.png   \n"," extracting: 00000/img00000012.png   \n"," extracting: 00000/img00000013.png   \n"," extracting: 00000/img00000014.png   \n"," extracting: 00000/img00000015.png   \n"," extracting: 00000/img00000016.png   \n"," extracting: 00000/img00000017.png   \n"," extracting: 00000/img00000018.png   \n"," extracting: 00000/img00000019.png   \n"," extracting: 00000/img00000020.png   \n"," extracting: 00000/img00000021.png   \n"," extracting: 00000/img00000022.png   \n"," extracting: 00000/img00000023.png   \n"," extracting: 00000/img00000024.png   \n"," extracting: 00000/img00000025.png   \n"," extracting: 00000/img00000026.png   \n"," extracting: dataset.json            \n"]}],"source":["!unzip /kaggle/working/smaller_avantgarde_128.zip"]},{"cell_type":"markdown","metadata":{},"source":["### train"]},{"cell_type":"markdown","metadata":{},"source":["* Can continue training from a model with e.g. `--resume=/kaggle/input/stylegan3/pytorch/520ep/1/network-snapshot-000560.pkl`\n","* parameters mostly chosen per the [StyleGAN3 guidelines](https://github.com/NVlabs/stylegan3/blob/main/docs/configs.md#general-guidelines) + cbase value selected for training efficiency and batchsize from trial and error. \n","* see [StyleGAN3 train-help](https://github.com/NVlabs/stylegan3/blob/main/docs/train-help.txt) for more information on training parameters\n","\n","Note: with 2 GPUS in kaggle, training took 11 hours to reach 560 epochs."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T10:00:49.287727Z","iopub.status.busy":"2024-06-19T10:00:49.287334Z","iopub.status.idle":"2024-06-19T10:24:05.151187Z","shell.execute_reply":"2024-06-19T10:24:05.149888Z","shell.execute_reply.started":"2024-06-19T10:00:49.287686Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Training options:\n","{\n","  \"G_kwargs\": {\n","    \"class_name\": \"training.networks_stylegan3.Generator\",\n","    \"z_dim\": 512,\n","    \"w_dim\": 512,\n","    \"mapping_kwargs\": {\n","      \"num_layers\": 2\n","    },\n","    \"channel_base\": 32768,\n","    \"channel_max\": 1024,\n","    \"magnitude_ema_beta\": 0.9988915792636801,\n","    \"conv_kernel\": 1,\n","    \"use_radial_filters\": true\n","  },\n","  \"D_kwargs\": {\n","    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n","    \"block_kwargs\": {\n","      \"freeze_layers\": 0\n","    },\n","    \"mapping_kwargs\": {},\n","    \"epilogue_kwargs\": {\n","      \"mbstd_group_size\": 2\n","    },\n","    \"channel_base\": 16384,\n","    \"channel_max\": 512\n","  },\n","  \"G_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08,\n","    \"lr\": 0.0025\n","  },\n","  \"D_opt_kwargs\": {\n","    \"class_name\": \"torch.optim.Adam\",\n","    \"betas\": [\n","      0,\n","      0.99\n","    ],\n","    \"eps\": 1e-08,\n","    \"lr\": 0.002\n","  },\n","  \"loss_kwargs\": {\n","    \"class_name\": \"training.loss.StyleGAN2Loss\",\n","    \"r1_gamma\": 0.5,\n","    \"blur_init_sigma\": 10,\n","    \"blur_fade_kimg\": 200.0\n","  },\n","  \"data_loader_kwargs\": {\n","    \"pin_memory\": true,\n","    \"prefetch_factor\": 2,\n","    \"num_workers\": 3\n","  },\n","  \"training_set_kwargs\": {\n","    \"class_name\": \"training.dataset.ImageFolderDataset\",\n","    \"path\": \"/kaggle/working/00000\",\n","    \"use_labels\": false,\n","    \"max_size\": 27,\n","    \"xflip\": false,\n","    \"resolution\": 128,\n","    \"random_seed\": 0\n","  },\n","  \"num_gpus\": 2,\n","  \"batch_size\": 32,\n","  \"batch_gpu\": 16,\n","  \"metrics\": [],\n","  \"total_kimg\": 25000,\n","  \"kimg_per_tick\": 4,\n","  \"image_snapshot_ticks\": 5,\n","  \"network_snapshot_ticks\": 5,\n","  \"random_seed\": 0,\n","  \"ema_kimg\": 10.0,\n","  \"augment_kwargs\": {\n","    \"class_name\": \"training.augment.AugmentPipe\",\n","    \"xflip\": 1,\n","    \"rotate90\": 1,\n","    \"xint\": 1,\n","    \"scale\": 1,\n","    \"rotate\": 1,\n","    \"aniso\": 1,\n","    \"xfrac\": 1,\n","    \"brightness\": 1,\n","    \"contrast\": 1,\n","    \"lumaflip\": 1,\n","    \"hue\": 1,\n","    \"saturation\": 1\n","  },\n","  \"ada_target\": 0.6,\n","  \"run_dir\": \"/kaggle/working/stylegan3/training-runs/00000-stylegan3-r-00000-gpus2-batch32-gamma0.5\"\n","}\n","\n","Output directory:    /kaggle/working/stylegan3/training-runs/00000-stylegan3-r-00000-gpus2-batch32-gamma0.5\n","Number of GPUs:      2\n","Batch size:          32 images\n","Training duration:   25000 kimg\n","Dataset path:        /kaggle/working/00000\n","Dataset size:        27 images\n","Dataset resolution:  128\n","Dataset labels:      False\n","Dataset x-flips:     False\n","\n","Creating output directory...\n","Launching processes...\n","Loading training set...\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n","  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n","/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n","  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n","\n","Num images:  27\n","Image shape: [3, 128, 128]\n","Label shape: [0]\n","\n","Constructing networks...\n","Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n","Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n","\n","Generator                     Parameters  Buffers  Output shape         Datatype\n","---                           ---         ---      ---                  ---     \n","mapping.fc0                   262656      -        [16, 512]            float32 \n","mapping.fc1                   262656      -        [16, 512]            float32 \n","mapping                       -           512      [16, 16, 512]        float32 \n","synthesis.input.affine        2052        -        [16, 4]              float32 \n","synthesis.input               1048576     3081     [16, 1024, 36, 36]   float32 \n","synthesis.L0_36_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L0_36_1024          1049600     157      [16, 1024, 36, 36]   float16 \n","synthesis.L1_36_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L1_36_1024          1049600     157      [16, 1024, 36, 36]   float16 \n","synthesis.L2_36_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L2_36_1024          1049600     157      [16, 1024, 36, 36]   float16 \n","synthesis.L3_52_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L3_52_1024          1049600     169      [16, 1024, 52, 52]   float16 \n","synthesis.L4_52_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L4_52_1024          1049600     157      [16, 1024, 52, 52]   float16 \n","synthesis.L5_52_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L5_52_1024          1049600     157      [16, 1024, 52, 52]   float16 \n","synthesis.L6_84_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L6_84_1024          1049600     169      [16, 1024, 84, 84]   float16 \n","synthesis.L7_84_1024.affine   525312      -        [16, 1024]           float32 \n","synthesis.L7_84_1024          1049600     157      [16, 1024, 84, 84]   float16 \n","synthesis.L8_84_813.affine    525312      -        [16, 1024]           float32 \n","synthesis.L8_84_813           833325      157      [16, 813, 84, 84]    float16 \n","synthesis.L9_148_609.affine   417069      -        [16, 813]            float32 \n","synthesis.L9_148_609          495726      169      [16, 609, 148, 148]  float16 \n","synthesis.L10_148_456.affine  312417      -        [16, 609]            float32 \n","synthesis.L10_148_456         278160      157      [16, 456, 148, 148]  float16 \n","synthesis.L11_148_342.affine  233928      -        [16, 456]            float32 \n","synthesis.L11_148_342         156294      157      [16, 342, 148, 148]  float16 \n","synthesis.L12_148_256.affine  175446      -        [16, 342]            float32 \n","synthesis.L12_148_256         87808       25       [16, 256, 148, 148]  float16 \n","synthesis.L13_128_256.affine  131328      -        [16, 256]            float32 \n","synthesis.L13_128_256         65792       25       [16, 256, 128, 128]  float16 \n","synthesis.L14_128_3.affine    131328      -        [16, 256]            float32 \n","synthesis.L14_128_3           771         1        [16, 3, 128, 128]    float16 \n","synthesis                     -           -        [16, 3, 128, 128]    float32 \n","---                           ---         ---      ---                  ---     \n","Total                         18019940    5564     -                    -       \n","\n","Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n","\n","Discriminator  Parameters  Buffers  Output shape         Datatype\n","---            ---         ---      ---                  ---     \n","b128.fromrgb   512         16       [16, 128, 128, 128]  float16 \n","b128.skip      32768       16       [16, 256, 64, 64]    float16 \n","b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n","b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n","b128           -           16       [16, 256, 64, 64]    float16 \n","b64.skip       131072      16       [16, 512, 32, 32]    float16 \n","b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n","b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n","b64            -           16       [16, 512, 32, 32]    float16 \n","b32.skip       262144      16       [16, 512, 16, 16]    float16 \n","b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n","b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n","b32            -           16       [16, 512, 16, 16]    float16 \n","b16.skip       262144      16       [16, 512, 8, 8]      float16 \n","b16.conv0      2359808     16       [16, 512, 16, 16]    float16 \n","b16.conv1      2359808     16       [16, 512, 8, 8]      float16 \n","b16            -           16       [16, 512, 8, 8]      float16 \n","b8.skip        262144      16       [16, 512, 4, 4]      float32 \n","b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n","b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n","b8             -           16       [16, 512, 4, 4]      float32 \n","b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n","b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n","b4.fc          4194816     -        [16, 512]            float32 \n","b4.out         513         -        [16, 1]              float32 \n","---            ---         ---      ---                  ---     \n","Total          23882369    352      -                    -       \n","\n","Setting up augmentation...\n","Distributing across 2 GPUs...\n","Setting up training phases...\n","Exporting sample images...\n","Initializing logs...\n","2024-06-19 10:04:27.504463: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-19 10:04:27.504577: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-19 10:04:27.618169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Training for 25000 kimg...\n","\n","tick 0     kimg 0.0      time 4m 02s       sec/tick 24.2    sec/kimg 757.46  maintenance 217.8  cpumem 2.59   gpumem 14.12  reserved 14.23  augment 0.000\n","tick 1     kimg 4.0      time 9m 21s       sec/tick 281.8   sec/kimg 70.44   maintenance 37.1   cpumem 3.01   gpumem 5.99   reserved 10.58  augment 0.000\n","tick 2     kimg 8.0      time 14m 04s      sec/tick 282.5   sec/kimg 70.62   maintenance 0.1    cpumem 3.01   gpumem 5.98   reserved 10.58  augment 0.000\n","tick 3     kimg 12.0     time 18m 46s      sec/tick 282.5   sec/kimg 70.63   maintenance 0.1    cpumem 3.01   gpumem 5.98   reserved 10.58  augment 0.001\n","^C\n","\n","Aborted!\n"]}],"source":["!python /kaggle/working/stylegan3/train.py \\\n","    --outdir=/kaggle/working/stylegan3/training-runs \\\n","    --cfg=stylegan3-r --data=/kaggle/working/00000 --snap=20 \\\n","    --gpus=2 --batch=32 --gamma=0.5 --mbstd-group=2 --cbase=16384 \\\n","    --metrics=none"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5101575,"sourceId":8539826,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":57308,"sourceId":68725,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
